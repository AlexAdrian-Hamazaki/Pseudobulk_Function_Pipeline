conda.enabled = true

// Conda Environments

params.python3_9 = "/home/aadrian/anaconda3/envs/PseudoPipelineEnv"

// 
params.tissue_datasets = "/pipeline42/datasets/AlexA/SC/human_protein_atlas/tissue_datasets/rna_single_cell_read_count/*"
params.sc_cluster_meta = "/pipeline42/datasets/AlexA/SC/human_protein_atlas/collapsed_datasets/rna_single_cell_cluster_description.tsv"
params.genes_meta = "/space/grp/aadrian/Pseudobulk_Function_Pipeline_HighRes/bin/preprocessing/preprocessGenes_pipe/data/genes/humanAllGenes.csv"
params.curated_cutoffs = "/space/grp/aadrian/Pseudobulk_Function_Pipeline_HighRes/bin/preprocessing/preprocessSC_pipe/data/curatedCutoffs.csv"
params.pc_map = "/space/grp/aadrian/Pseudobulk_Function_Pipeline_HighRes/bin/preprocessing/preprocessGenes_pipe/data/genes/humanPCGenes.csv"


// workDir is where the work directories are run and stored
workDir = "/scratch/aadrian/preprocessSC_pipe/work"


// Staging Dir is where the large dataframes are
params.stagingDir = "/pipeline42/datasets/AlexA"


// Executor Settings
executor {
    name = 'local'
    queueSize = 10
    pollInterval = '30 sec'
    cpus = 32
}
//process.executor = 'slurm'